##################################################################################
# Authors: Ayush Anand, Pritam De, Sairaj Menon, Sritej Reddy,
#          Aaron Steele, Shubham Verma
# Course: CSE 515 Fall 2021, Arizona State University
# Professor: K. Sel√ßuk Candan
# Project: Course Project Phase 3
# File: io.py
# 
# Description: A file containing a number of functions used for file I/O, such
# as reading in and processing images, as well as saving output data.
##################################################################################

import numpy as np
import os
import skimage.io
import glob
import re
import pickle
import matplotlib.pyplot as plt
import math
import random
from pathlib import Path

# Various arrays used for input comparison.
TYPE = ['cc', 'con', 'emboss', 'jitter', 'neg', 'noise01', 'noise02', 'original', 'poster', 'rot', 'smooth', 'stipple']
DIMRED = ['pca', 'svd', 'lda', 'kmeans']
MODEL = ['color', 'elbp', 'hog', 'latent']
CLASSIFIER = ['svm', 'dt', 'ppr']
NUM_SUBJECTS = 40
IMG_PER_SUBJECT = 10

def read_images(input_folder, imgtype = None, subjectid = None):
    """
    Reads in files for the project from a specified input folder of a given image type. Is able
    to read all images of a certain type, all images of a subject, or all images of a certain type
    depending on if certain input parameters are specified. At least one of these parameters must
    be specified!

    If an image type is specified with no subject ID, all images of that type are read in. Similarly,
    if a subject ID is specified with no image type, all images of that subject are read in. If both
    are specified the 10 images of the subject corresponding to both parameters are read.

    Parameters:
        input_folder: Folder from which images are read.
        imgtype: Optional parameter which specifies the type of image to read.
        subjectid: Optional parameter which specifies the subject  to read images of.

    Returns:
        A dictionary where image arrays are referenced by their filename.
    """
    output = {}
    # Sanity check
    # if imgtype == None and subjectid == None:
    #     print("Error in 'read_images()': You must specify at least one option!")
    #     exit(1)
    
    # Note that this complex regex method must be used due to some subjects not having all 10 images for some reason.
    if imgtype == None and subjectid == None:
        pattern = "image-[a-z0-9]+-[0-9]{1,2}-[0-9]{1,2}.png"
    elif imgtype != None and subjectid == None:
        pattern = "image-" + imgtype + "-[0-9]{1,2}-[0-9]{1,2}.png"
    elif imgtype == None and subjectid != None:
        pattern = "image-[a-z0-9]+-" + str(subjectid) + "-[0-9]{1,2}.png"
    else:
        pattern = "image-" + imgtype + "-" + str(subjectid) + "-[0-9]{1,2}.png"

    # Get filenames and filter for the correct images
    file_list = sorted([x.replace(f"{input_folder}/", '') for x in glob.glob(f"{input_folder}/*.png") if re.search(pattern, x)])
    file_list = [os.path.basename(x) for x in file_list]
    
    for filename in file_list:
        # This line seems to cause issues on different PCs. Might need to fix this.
        # To ensure consistency, we use skimage to scale all gray values to the range [0, 1]
        image = skimage.img_as_float(skimage.io.imread(os.path.join(input_folder, filename), as_gray=True))
        match_type = "image-([a-z0-9]+)-[0-9]{1,2}-[0-9]{1,2}.png"
        match_subject = "image-[a-z0-9]+-([0-9]{1,2})-[0-9]{1,2}.png"
        match_id = "image-[a-z0-9]+-[0-9]{1,2}-([0-9]{1,2}).png"
        output[filename] = {}
        output[filename]['image'] = image
        output[filename]['type'] = re.search(match_type, filename).group(1)
        output[filename]['subject'] = re.search(match_subject, filename).group(1)
        output[filename]['id'] = re.search(match_id, filename).group(1)
    return output

def write_pairs(output_folder, pairs, model, dim_red, k, tasknum, miscstr):
    """
    Writes subject/type-weight pairs to a file. The input should be an array, where each entry is an array of
    tuples of the form '(label, value)' (where the label is the subject or type). These are written, with each line
    of the form:
        '1# label1,value1 # label2,value2 # ...'
    
    Note that these are listed in descending order.

    Parameters:
        output_folder: File to which this data is written.
        pairs: The array of lists of pairs as described above.
        model: The model used for feature extraction.
        dim_red: The dimensionality reduction method used to create the pairs.
        k: The number of latent semantics generated.
        tasknum: The number of the task which generated this file.
        miscstr: A string to indicate whether the file was generated by type or subject data.
    """
    filename = f"pairs_{tasknum}_{model}_{dim_red}_{miscstr}_{k}.txt"
    with open(os.path.join(output_folder, filename), "w") as f:
        f.write(f"{model} {dim_red} {k} {tasknum} {miscstr}\n")
        for i in range(len(pairs)):
            # We sort before saving the values, just to be sure
            tuple_list = sorted(pairs[i], key=lambda x: x[1], reverse=True)
            f.write(f"{i+1}")
            # Labels and values are separated with a comma, then entries are separated with '#'
            for label, value in tuple_list:
                f.write(f"# {label},{value} ")
            f.write("\n")

def str_to_tuple(input_str):
    """
    Helper function used to help parse saved pairs. Takes an input string with two comma-separated values as input,
    where the first value is the subject/type and the second value is the weight.

    Parameters:
        input_str: An input string of the form "subject,value" or "type,value", depending on the type of pair.

    Returns:
        A tuple of the parsed string, with the value returned as a Numpy flaot64 type.
    """
    temp_arr = input_str.split(',')
    return (temp_arr[0], np.float64(temp_arr[1]))

def read_pairs(input_file):
    """
    Reads subject/type-weight pairs saved to a file with the above function 'write_pairs'. Returns an array, where each entry
    is an array of tuples containining the subject/type, then the value in decreasing order.

    Parameters:
        input_file: Input file from which to read subject/type-weight pairs.
    
    Returns:
        An array containing arrays of tuples with the subject/type and values in descending order. The ith entry in the
        returned array corresponds to the i+1th latent semantic.
    """
    output = []
    with open(input_file, "r") as f:
        lines = f.readlines()
        [model, dim_red, k] = lines[0].split(' ')
        for line in lines[1::]:
            # We parse all except the first element (which indicates the number of the latent semantic) into tuples
            # using the map function.
            output.append(list(map(str_to_tuple, [x.strip() for x in line.split('#')][1::])))
    return model, dim_red, k, output

def read_image(filename):
    """
    Reads and returns a single selected image, used for Tasks 5-7.
    """
    return skimage.img_as_float(skimage.io.imread(filename, as_gray=True))

def write_latent_semantics(output_folder, data, model, dim_red, k):
    """
    Writes all information in 'data' to a pickle file. 'Data' should be an array with a specific format containing
    various information about the latent semantics. In particular, it should be of the form:
        [model, dim_red, k, image_dict, pairs, output from dimensional reduction]
    
    This function chooses the filename, so specify the directory carefully.

    Parameters:
        output_folder: The folder to which the file is written.
        data: The data to be saved. See the above description for details.
        model: The model ('color', 'elbp', or 'hog') used for feature extraction.
        dim_red: The method used for dimensional reduction ('pca', 'svd', 'lda', or 'kmeans').
        k: The number of latent semantics generated.
    """
    pickle.dump(data, open(os.path.join(output_folder, f"{model}_{dim_red}_{k}.p"), "wb"))

def read_pickle_file(input_file):
    """
    Reads latent semantics and various data from a specified file. The file here should be one written by
    io.write_latent_semantics().

    Parameters:
        input_file: File from which to read the data.

    Returns:
        An array with information. If reading latent semantics, is of the form:
        [model, dim_red, k, image_dict, pairs, output from dimensional reduction]
    """
    return pickle.load(open(input_file, "rb"))

def write_similarity_matrix(output_folder, sim_matrix, index_array, model, dim_red, k, tasknum, subject_bool):
    """
    Writes similarity matrix to an auto-named file.

    Parameters:
        output_folder: The folder to which the file is written.
        sim_matrix: The similarity matrix written.
        index_array: An array where the order of elements indicates the order of the subjects/types in the matrix.
        model: The model ('color', 'elbp', or 'hog') used for feature extraction.
        dim_red: The method used for dimensional reduction ('pca', 'svd', 'lda', or 'kmeans').
        k: The number of latent semantics generated.
        tasknum: The number of task from which this was generated (tasks 1-4).
        subject_bool: Boolean to indicate whether the matrix is a subject-subject or type-type similarity matrix.
    """
    suffix = "ss" if subject_bool else "tt"
    pickle.dump([sim_matrix, index_array, suffix], open(os.path.join(output_folder, f"{tasknum}_{model}_{dim_red}_{k}_{suffix}.p"), "wb"))

def create_and_save_top_k_image(distances, image_dict, compare_id, original_image, k, output_file):
    """
    Helper function used to create and save a visual representation of the top k matching results for
    a given image ID (for images in a target folder).
    While there is nothing returned by this function, it does save the matplotlib image to the file 'output_file'.
    Parameters:
        distances: A 2D array containing image ID's for the folder and the distance vectors (or other similarity
            measure) as the first and second elements in each row, respectively. This should be sorted BEFORE
            running this function.
        feature_dict: A dictionary containing all features for an image. The image data is stored here.
        compare_id: The ID of the image to which all other images are compared.
        feature: The image feature ('color', 'ELBP', or 'HOG') which was used to compare the images and find the k
            most similar results. If this value is 'all', a slightly different title is printed to reflect that all
            features were considered in the results.
        k: The number of results to return.
        output_file: The file to which the image with results should be written.
    """
    # Creates a figure with subplots thare are 5 wide and has enough rows to hold all images.
    fig, axarr=plt.subplots(nrows=math.ceil(k/5) + 1, ncols=5, figsize=(18, math.ceil(k/20)*12))
    fig.tight_layout(rect=[0, 0.03, 1, 0.95])
    axarr = axarr.flatten()
    # Iterates through each subplot accordingly. This isn't pretty, but essentially hides all subplots on the
    # top row except the compared image. Following rows contain the top images, listed in descending order.
    for i in range(5):
        if i == 2:
            axarr[i].imshow(original_image, cmap='gray')
            axarr[i].set_xticks([])
            axarr[i].set_yticks([])
            axarr[i].set_title(f"Original Image ID: {compare_id}")
        elif i < 5:
            axarr[i].get_xaxis().set_visible(False)
            axarr[i].get_yaxis().set_visible(False)
            axarr[i].axis('off')
    j = 5
    for (image_id, value) in distances:
        axarr[j].imshow(image_dict[image_id]['image'], cmap='gray')
        axarr[j].set_xticks([])
        axarr[j].set_yticks([])
        axarr[j].set_title(f"Image ID: {image_id}\nValue: {value}")
        j += 1
    # Hide the remaining slots in the image, if any
    while j < (5 * (math.ceil(j/5))):
        axarr[j].get_xaxis().set_visible(False)
        axarr[j].get_yaxis().set_visible(False)
        axarr[j].axis('off')
        j += 1

    plt.suptitle(f"Top {k} results for image with ID '{compare_id}':", fontsize=18)
    plt.savefig(output_file)

def save_sim_subject_or_type(output_file, min_type, min_value, min_dict, misc, input_image, semantics_file):
    """
    Saves the result of Tasks 6 or 7 to a file, listing the matching subject or type as well as a ranking
    of other subjects or types.

    Parameters:
        output_file: The file to which output is written.
        min_type: The minimum subject/type.
        min_value: The score for the assigned subject/type.
        min_dict: A dictionary containing the subjects/types and their values.
        misc: A miscellaneous string to create proper printing
        input_image: The filename compared to the database
        semantics_file: The filename of the semantics file
    """
    with open(output_file, "w") as f:
        f.write(f"When using all images mapped to the latent feature space, the most similar {misc}\n")
        f.write(f"to input image '{input_image}' when using latent semantic file '{semantics_file}'\n")
        f.write(f"is {min_type} with value {min_value}.\n\n")
        f.write(f"For reference, the ranking of {misc}s are:\n")
        for k, v in sorted(min_dict.items(), key=lambda item: item[1]):
            f.write(f"{k}:\t{v}\n")

def save_simgraph_results(output_file, graph_dict, subject_tuples, n, miscstr):
    """
    Saves the results of Tasks 8 and 9 to a file. Prints the graph dictionary, then the 'm'
    most significant nodes in the graph.

    Parameters:
        output_file: The output file to which results are written.
        graph_dict: A graph dictionary generated earlier in the Task
        subject_tuples: Lists of the top 'm' tuples, with the subject and the node's score.
        n: The number of edges from each node
        miscstr: A miscellaneous string indicating that ASCOS++ or PPR was used.
    """
    m = len(subject_tuples)
    with open(output_file, "w") as f:
        f.write(f"The similarity graph, generated with {n} edges from each node, is:\n")
        for key, value in graph_dict.items():
            f.write(f"{key + 1}:\t{[[x[0] + 1, x[1] + 1] for x in value]}\n")
        f.write("\n\n")
        f.write(f"The most significant {m} subjects in the collection when using {miscstr} are:\n")
        for (x, y) in subject_tuples:
            f.write(f"{x}:\t{y}\n")

def save_classification_results(output_folder, output_filename, classified_tuples, accuracy_stats, overall_accuracy):
    """
    Saves the classification results from Tasks 1-3 of Phase 3 of the project. Prints
    the labels assigned to each input as well as the false positive/miss rates.
    
    Parameters:
        output_folder: The folder to which these results should be saved.
        output_filename: The name of the file to which these results are saved.
        classified_tuples: A list of tuples of the form '(image_name, 1, classification)'.
            These are the labels assigned to the originally unlabeled images.
        accuracy_stats: A list of tuples of the form '(class, FPR, MR)'. This is the 
            false positive and miss rates for each class.
    """
    output_file = os.path.join(output_folder, output_filename)
    filename_maxlen = len(max(classified_tuples, key=lambda x:len(x[0]))[0])
    class_maxlen = len(str(max(accuracy_stats, key=lambda x:len(str(x[0])))[0]))
    with open(output_file, "w") as f:
        f.write("The input images were classified as follows:\n")
        for tup in classified_tuples:
            f.write(f"{tup[0] +':':{filename_maxlen+1}}\t{tup[1]}\n")
        f.write("\nThe classes had the following false positive rates:\n")
        for tup in accuracy_stats:
            f.write(f"{str(tup[0])+':':{class_maxlen+1}}\t{round(tup[1], 5)}\n")
        f.write("\nThe classes had the following miss rates:\n")
        for tup in accuracy_stats:
            f.write(f"{str(tup[0])+':':{class_maxlen+1}}\t{round(tup[2], 5)}\n")
        f.write(f"\nOverall accuracy: {overall_accuracy}")
    print(f"Results saved to '{output_folder}/{output_filename}'")

def print_start_status(tasknum, args):
    """
    Prints the status of a program on startup. This gives information about what task
    is being run as well as various parameters given to the program.
    
    Parameters:
        tasknum: An integer (from 1-8) specifying the task.
        args: An array of arguments. This varies depending on the task.
    """
    # In the case of the first 3 tasks
    if tasknum >= 1 and tasknum <= 3:
        input_folder, model, dim_red_technique, k, output_folder, latent_semantic_file, classify_folder, classifier = args
        print('\n' + '#' * 60)
        print(f"Task {tasknum} was run with the following parameters:")
        if latent_semantic_file is None:
            print("bar")
    print("foo")
    
def get_int_from_user(input_str):
    """
    Gets an integer as input from the user and loops until a valid integer is returned.
    
    Parameters:
        input_str: String printed to the terminal before selecting user input.
    
    Returns:
        The validated user integer input.
    """
    valid_int = False
    while not valid_int:
        try:
            user_input = int(input(input_str))
        except:
            print("Invalid input. Please enter an integer...")
        if user_input < 1:
            print("Please enter a number of size at least 1.")
        else:
            valid_int = True
    return user_input

def save_query_results(input_folder, output_folder, query_image, query_image_name, processed_query_vector, returned_images, tasknum, t):
    """
    Saves the results of a query in Tasks 4-5 to a file. This file is in binary format
    to make storage/retrieval easy.
    
    TODO: It might be useful to save all images here? Can also just save the original dictionary or
    the index structure.
    
    Parameters:
        input_folder: Input folder from which images were read.
        output_folder: Folder to which query results should be saved.
        query_image: Image used for the query.
        returned_images: An array containing the names of the images returned by the query.
        tasknum: The task which generated the results (should be '4' or '5').
        t: The number of results returned.
    """
    # Note that the name has a random element so we don't overwrite old files.
    filename = f"query_results_{input_folder.replace(r'/', '-')}_{tasknum}_{random.randint(1000,9999)}.p"
    to_dump = [input_folder, query_image, query_image_name, processed_query_vector, tasknum, returned_images, t]
    pickle.dump(to_dump, open(os.path.join(output_folder, filename), "wb"))
    print(f"Saved query results to {os.path.join(output_folder, filename)}!\nThis file can be used in Tasks 6-7.")
    
def read_query_results(query_file_location):
    """
    Reads query results stored by the 'save_query_results' function above.
    
    Parameters:
        query_file_location: File from which to read query results.
        
    Returns:
        An array of the following form: [input_folder, query_image, tasknum, returned_images], where:
        
            input_folder: Input folder from which images were read (for the index structure/query).
            query_image: Image used for the query in the index structure.
            tasknum: A number indicating the task which generated the results (should be '4' or '5').
            returned_images: An array containing the images returned by the query.
            t: The number of images in the query (the full vector is saved).
    """
    return pickle.load(open(query_file_location, "rb"))

def display_query_results(image_dict, query_image, query_image_name, query_results, output_folder = None, output_filename = None):
    """
    Helper function used to display query results to the terminal for easier relevance feedback.
    """
    t = len(query_results)
    # Creates a figure with subplots thare are 5 wide and has enough rows to hold all images.
    fig, axarr=plt.subplots(nrows=math.ceil(t/5) + 1, ncols=5, figsize=(18, math.ceil(t/20)*12))
    fig.tight_layout(rect=[0, 0.03, 1, 0.95])
    axarr = axarr.flatten()
    #plt.ion()
    #plt.show()
    # Iterates through each subplot accordingly. This isn't pretty, but essentially hides all subplots on the
    # top row except the compared image. Following rows contain the top images, listed in descending order.
    for i in range(5):
        if i == 2:
            axarr[i].imshow(query_image, cmap='gray')
            axarr[i].set_xticks([])
            axarr[i].set_yticks([])
            axarr[i].set_title(f"Query Image Filename: {query_image_name}")
        elif i < 5:
            axarr[i].get_xaxis().set_visible(False)
            axarr[i].get_yaxis().set_visible(False)
            axarr[i].axis('off')
    j = 5
    for image_id in query_results:
        axarr[j].imshow(image_dict[image_id]['image'], cmap='gray')
        axarr[j].set_xticks([])
        axarr[j].set_yticks([])
        axarr[j].set_title(f"Image Name: {image_id}")
        j += 1
    # Hide the remaining slots in the image, if any
    while j < (5 * (math.ceil(j/5))):
        axarr[j].get_xaxis().set_visible(False)
        axarr[j].get_yaxis().set_visible(False)
        axarr[j].axis('off')
        j += 1
    plt.suptitle(f"Top {t} query results for query image '{query_image_name}':", fontsize=18)
    #plt.draw()
   #plt.pause(0.001)
    #plt.show(block=False)
    if output_folder is not None:
        plt.savefig(os.path.join(output_folder, output_filename))
        print(f"Results saved to '{os.path.join(output_folder, output_filename)}'")
    # plt.show()
